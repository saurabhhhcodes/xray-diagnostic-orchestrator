{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dadda93c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 1: Imports & System Setup\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "from glob import glob\n",
    "from itertools import chain\n",
    "from sklearn.model_selection import train_test_split\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.applications import DenseNet121\n",
    "from tensorflow.keras.layers import Dense, GlobalAveragePooling2D\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint, ReduceLROnPlateau, EarlyStopping\n",
    "\n",
    "# Reproducibility\n",
    "SEED = 2026\n",
    "np.random.seed(SEED)\n",
    "tf.random.set_seed(SEED)\n",
    "\n",
    "print(f\"TensorFlow Version: {tf.__version__}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30d66de0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 2: Smart Data Loader (Robust)\n",
    "# --- SMART PATH DETECTION ---\n",
    "print(\"Searching for dataset files...\")\n",
    "csv_files = glob('/kaggle/input/**/Data_Entry_2017.csv', recursive=True)\n",
    "\n",
    "if not csv_files:\n",
    "    raise FileNotFoundError(\"Could not find Data_Entry_2017.csv. Please check the 'Input' sidebar in Kaggle and add the 'NIH Chest X-rays' dataset.\")\n",
    "\n",
    "csv_path = csv_files[0]\n",
    "dataset_root = os.path.dirname(csv_path)\n",
    "print(f\"Found dataset at: {dataset_root}\")\n",
    "\n",
    "# Map all image paths\n",
    "image_paths = glob(os.path.join(dataset_root, '**', '*.png'), recursive=True)\n",
    "print(f\"Found {len(image_paths)} images.\")\n",
    "\n",
    "if len(image_paths) == 0:\n",
    "    raise FileNotFoundError(\"Found CSV but no images! Check dataset structure.\")\n",
    "\n",
    "path_map = {os.path.basename(x): x for x in image_paths}\n",
    "\n",
    "# --- DATA PROCESSING ---\n",
    "data = pd.read_csv(csv_path)\n",
    "data['path'] = data['Image Index'].map(path_map.get)\n",
    "data = data[data['path'].notnull()]\n",
    "\n",
    "# Handle Multi-Labels\n",
    "all_labels = np.unique(list(chain(*data['Finding Labels'].map(lambda x: x.split('|')).tolist())))\n",
    "all_labels = [x for x in all_labels if len(x)>0]\n",
    "print(f\"Classes: {all_labels}\")\n",
    "\n",
    "for label in all_labels:\n",
    "    data[label] = data['Finding Labels'].map(lambda finding: 1.0 if label in finding else 0.0)\n",
    "\n",
    "# Split by Patient ID (Prevent Data Leakage)\n",
    "train_ids, val_ids = train_test_split(data['Patient ID'].unique(), test_size=0.2, random_state=SEED)\n",
    "train_df = data[data['Patient ID'].isin(train_ids)]\n",
    "val_df = data[data['Patient ID'].isin(val_ids)]\n",
    "\n",
    "print(f\"Final Train Size: {len(train_df)} | Validation Size: {len(val_df)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ca49243",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 3: Data Augmentation & Generators\n",
    "IMG_SIZE = (224, 224) \n",
    "BATCH_SIZE = 32\n",
    "\n",
    "core_idg = ImageDataGenerator(\n",
    "    rescale=1./255, \n",
    "    samplewise_center=True, \n",
    "    samplewise_std_normalization=True, \n",
    "    horizontal_flip=True, \n",
    "    vertical_flip=False, \n",
    "    rotation_range=20, \n",
    "    zoom_range=0.15,\n",
    "    width_shift_range=0.1,\n",
    "    height_shift_range=0.1,\n",
    "    shear_range=0.1,\n",
    "    fill_mode='nearest'\n",
    ")\n",
    "\n",
    "def get_generator(df):\n",
    "    return core_idg.flow_from_dataframe(\n",
    "        dataframe=df,\n",
    "        directory=None,\n",
    "        x_col='path',\n",
    "        y_col=all_labels,\n",
    "        class_mode='raw',\n",
    "        batch_size=BATCH_SIZE,\n",
    "        shuffle=True,\n",
    "        target_size=IMG_SIZE\n",
    "    )\n",
    "\n",
    "train_gen = get_generator(train_df)\n",
    "val_gen = get_generator(val_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89bb3685",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 4: Build Model (DenseNet121)\n",
    "# Transfer Learning\n",
    "base_model = DenseNet121(weights='imagenet', include_top=False, input_shape=(224, 224, 3))\n",
    "\n",
    "x = base_model.output\n",
    "x = GlobalAveragePooling2D()(x)\n",
    "predictions = Dense(len(all_labels), activation='sigmoid')(x)\n",
    "\n",
    "model = Model(inputs=base_model.input, outputs=predictions)\n",
    "\n",
    "model.compile(optimizer=Adam(learning_rate=0.0001), \n",
    "              loss='binary_crossentropy', \n",
    "              metrics=['binary_accuracy', tf.keras.metrics.AUC(multi_label=True, name='auc')])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a68ae267",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 5: Train & Save\n",
    "# Fast Training: Check 10% of validation set per epoch to save time\n",
    "val_steps = len(val_gen) // 10 \n",
    "train_steps = len(train_gen)\n",
    "\n",
    "checkpoint = ModelCheckpoint(\n",
    "    'xray_model.h5', \n",
    "    monitor='val_auc', \n",
    "    verbose=1, \n",
    "    save_best_only=True, \n",
    "    mode='max'\n",
    ")\n",
    "\n",
    "early_stop = EarlyStopping(monitor='val_auc', patience=3, restore_best_weights=True)\n",
    "reduce_lr = ReduceLROnPlateau(monitor='val_auc', factor=0.1, patience=1)\n",
    "\n",
    "history = model.fit(\n",
    "    train_gen,\n",
    "    steps_per_epoch=train_steps, \n",
    "    validation_data=val_gen,\n",
    "    validation_steps=val_steps,\n",
    "    epochs=10, \n",
    "    callbacks=[checkpoint, early_stop, reduce_lr]\n",
    ")"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
